# Offline Tarteel Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Build a Python CLI that transcribes Quran recitation audio via mlx-whisper and identifies the exact surah:ayah being recited.

**Architecture:** Audio file -> mlx-whisper (tarteel-ai/whisper-base-ar-quran) -> Arabic text -> strip diacritics & normalize -> fuzzy match against 6,236 verse database -> output surah:ayah. Two-phase matching: n-gram overlap narrows to candidate surahs, then Levenshtein distance finds exact ayah.

**Tech Stack:** Python 3.13, mlx-whisper, numpy, python-Levenshtein, soundfile, uv

---

### Task 1: Project Scaffolding

**Files:**
- Create: `~/ai/projects/offline-tarteel/pyproject.toml`
- Create: `~/ai/projects/offline-tarteel/src/offline_tarteel/__init__.py`
- Create: `~/ai/projects/offline-tarteel/tests/__init__.py`

**Step 1: Initialize git repo**

```bash
cd ~/ai/projects/offline-tarteel
git init
```

**Step 2: Create pyproject.toml**

```toml
[project]
name = "offline-tarteel"
version = "0.1.0"
description = "Offline Quran verse recognition via speech-to-text"
requires-python = ">=3.12"
dependencies = [
    "mlx-whisper>=0.4.0",
    "numpy",
    "python-Levenshtein",
    "soundfile",
    "librosa",
]

[project.optional-dependencies]
dev = ["pytest"]

[project.scripts]
recognize = "offline_tarteel.cli:main"
```

**Step 3: Create venv and install deps**

```bash
cd ~/ai/projects/offline-tarteel
uv venv --python 3.13
source .venv/bin/activate
uv pip install -e ".[dev]"
```

**Step 4: Create empty package files**

Create `src/offline_tarteel/__init__.py` (empty) and `tests/__init__.py` (empty).

**Step 5: Create .gitignore**

```
.venv/
__pycache__/
*.pyc
*.egg-info/
dist/
data/test_audio/
```

**Step 6: Commit**

```bash
git add pyproject.toml src/ tests/ .gitignore
git commit -m "feat: scaffold offline-tarteel project"
```

---

### Task 2: Quran Text Database

**Files:**
- Create: `src/offline_tarteel/quran_db.py`
- Create: `tests/test_quran_db.py`
- Create: `scripts/fetch_quran_text.py`

**Step 1: Write the data fetch script**

`scripts/fetch_quran_text.py` fetches from `https://api.alquran.cloud/v1/quran/quran-uthmani` and saves to `data/quran.json`. The JSON structure per verse:

```python
{
    "surah": 1,
    "ayah": 1,
    "text_uthmani": "بِسْمِ ٱللَّهِ ٱلرَّحْمَـٰنِ ٱلرَّحِيمِ",
    "text_clean": "بسم الله الرحمن الرحيم",
    "surah_name": "الفاتحة",
    "surah_name_en": "Al-Faatiha"
}
```

The `text_clean` field is generated by stripping all Arabic diacritics (Unicode range 0x0610-0x061A, 0x064B-0x065F, 0x0670, 0x06D6-0x06DC, 0x06DF-0x06E4, 0x06E7-0x06E8, 0x06EA-0x06ED) and normalizing characters:
- أ إ آ ٱ -> ا
- ة -> ه
- ى -> ي

**Step 2: Run the fetch script**

```bash
python scripts/fetch_quran_text.py
```

Expected: `data/quran.json` with 6,236 entries.

**Step 3: Write test for quran_db module**

`tests/test_quran_db.py`:

```python
import pytest
from offline_tarteel.quran_db import QuranDB

@pytest.fixture
def db():
    return QuranDB()

def test_loads_all_verses(db):
    assert db.total_verses == 6236

def test_get_verse(db):
    v = db.get_verse(1, 1)
    assert v is not None
    assert "بسم" in v["text_clean"]

def test_surah_count(db):
    assert db.surah_count == 114

def test_search_clean_text(db):
    results = db.search("بسم الله الرحمن الرحيم")
    assert len(results) > 0
    assert results[0]["surah"] == 1
    assert results[0]["ayah"] == 1
```

**Step 4: Run test to verify it fails**

```bash
cd ~/ai/projects/offline-tarteel && .venv/bin/pytest tests/test_quran_db.py -v
```

Expected: FAIL (module not found)

**Step 5: Implement quran_db.py**

`src/offline_tarteel/quran_db.py`:

```python
import json
from pathlib import Path
from Levenshtein import ratio

DATA_PATH = Path(__file__).parent.parent.parent / "data" / "quran.json"

class QuranDB:
    def __init__(self, path: Path = DATA_PATH):
        with open(path) as f:
            self.verses = json.load(f)
        self._by_ref = {}
        self._by_surah = {}
        for v in self.verses:
            self._by_ref[(v["surah"], v["ayah"])] = v
            self._by_surah.setdefault(v["surah"], []).append(v)

    @property
    def total_verses(self):
        return len(self.verses)

    @property
    def surah_count(self):
        return len(self._by_surah)

    def get_verse(self, surah: int, ayah: int):
        return self._by_ref.get((surah, ayah))

    def get_surah(self, surah: int):
        return self._by_surah.get(surah, [])

    def search(self, text: str, top_k: int = 5) -> list[dict]:
        scored = []
        for v in self.verses:
            score = ratio(text, v["text_clean"])
            scored.append({**v, "score": score})
        scored.sort(key=lambda x: x["score"], reverse=True)
        return scored[:top_k]
```

**Step 6: Run tests**

```bash
cd ~/ai/projects/offline-tarteel && .venv/bin/pytest tests/test_quran_db.py -v
```

Expected: PASS

**Step 7: Commit**

```bash
git add scripts/fetch_quran_text.py data/quran.json src/offline_tarteel/quran_db.py tests/test_quran_db.py
git commit -m "feat: add Quran text database with fetch script and fuzzy search"
```

---

### Task 3: Text Normalizer

**Files:**
- Create: `src/offline_tarteel/normalizer.py`
- Create: `tests/test_normalizer.py`

**Step 1: Write test**

`tests/test_normalizer.py`:

```python
from offline_tarteel.normalizer import normalize_arabic

def test_strips_diacritics():
    assert normalize_arabic("بِسْمِ") == "بسم"

def test_normalizes_alef():
    assert normalize_arabic("أحمد إبراهيم آدم") == "احمد ابراهيم ادم"

def test_normalizes_alef_wasla():
    assert normalize_arabic("ٱلرَّحْمَـٰنِ") == "الرحمن"

def test_normalizes_taa_marbuta():
    assert normalize_arabic("رَحْمَةً") == "رحمه"

def test_normalizes_alef_maqsura():
    assert normalize_arabic("مُوسَى") == "موسي"

def test_full_basmala():
    result = normalize_arabic("بِسْمِ ٱللَّهِ ٱلرَّحْمَـٰنِ ٱلرَّحِيمِ")
    assert result == "بسم الله الرحمن الرحيم"
```

**Step 2: Run to verify fail**

```bash
cd ~/ai/projects/offline-tarteel && .venv/bin/pytest tests/test_normalizer.py -v
```

**Step 3: Implement normalizer.py**

```python
import re
import unicodedata

# Arabic diacritic Unicode ranges
_DIACRITICS = re.compile(
    '[\u0610-\u061A\u064B-\u065F\u0670\u06D6-\u06DC'
    '\u06DF-\u06E4\u06E7\u06E8\u06EA-\u06ED\u0640]'
)

# Character normalization map
_NORM_MAP = str.maketrans({
    '\u0623': '\u0627',  # أ -> ا
    '\u0625': '\u0627',  # إ -> ا
    '\u0622': '\u0627',  # آ -> ا
    '\u0671': '\u0627',  # ٱ -> ا
    '\u0629': '\u0647',  # ة -> ه
    '\u0649': '\u064A',  # ى -> ي
})

def normalize_arabic(text: str) -> str:
    text = _DIACRITICS.sub('', text)
    text = text.translate(_NORM_MAP)
    text = ' '.join(text.split())  # collapse whitespace
    return text
```

**Step 4: Run tests**

```bash
cd ~/ai/projects/offline-tarteel && .venv/bin/pytest tests/test_normalizer.py -v
```

Expected: PASS

**Step 5: Commit**

```bash
git add src/offline_tarteel/normalizer.py tests/test_normalizer.py
git commit -m "feat: add Arabic text normalizer for diacritics and char normalization"
```

---

### Task 4: Verse Matcher (Two-Phase)

**Files:**
- Create: `src/offline_tarteel/matcher.py`
- Create: `tests/test_matcher.py`

**Step 1: Write test**

`tests/test_matcher.py`:

```python
import pytest
from offline_tarteel.matcher import VerseMatcher

@pytest.fixture
def matcher():
    return VerseMatcher()

def test_match_basmala(matcher):
    result = matcher.match("بسم الله الرحمن الرحيم")
    assert result is not None
    assert result["surah"] == 1
    assert result["ayah"] == 1

def test_match_fatiha_second_verse(matcher):
    result = matcher.match("الحمد لله رب العالمين")
    assert result is not None
    assert result["surah"] == 1
    assert result["ayah"] == 2

def test_match_with_context(matcher):
    # After identifying a verse in Al-Fatiha, next match should bias toward Al-Fatiha
    matcher.match("بسم الله الرحمن الرحيم")
    result = matcher.match("الحمد لله رب العالمين")
    assert result["surah"] == 1
    assert result["ayah"] == 2

def test_match_ayat_al_kursi(matcher):
    text = "الله لا اله الا هو الحي القيوم"
    result = matcher.match(text)
    assert result is not None
    assert result["surah"] == 2
    assert result["ayah"] == 255

def test_match_imperfect_transcription(matcher):
    # Simulate whisper output with slight errors
    text = "بسم الله الرحمان الرحيم"  # extra alef in الرحمان
    result = matcher.match(text)
    assert result is not None
    assert result["surah"] == 1
    assert result["ayah"] == 1
```

**Step 2: Run to verify fail**

```bash
cd ~/ai/projects/offline-tarteel && .venv/bin/pytest tests/test_matcher.py -v
```

**Step 3: Implement matcher.py**

`src/offline_tarteel/matcher.py`:

```python
from Levenshtein import ratio
from offline_tarteel.quran_db import QuranDB
from offline_tarteel.normalizer import normalize_arabic

class VerseMatcher:
    def __init__(self):
        self.db = QuranDB()
        self._last_surah = None
        self._last_ayah = None

    def match(self, transcription: str, threshold: float = 0.4) -> dict | None:
        text = normalize_arabic(transcription)
        if not text.strip():
            return None

        best = None
        best_score = 0.0

        # Phase 1: If we have context, search nearby verses first
        if self._last_surah is not None:
            nearby = self._search_nearby(text)
            if nearby and nearby["score"] > 0.6:
                best = nearby
                best_score = nearby["score"]

        # Phase 2: N-gram surah narrowing
        candidate_surahs = self._narrow_surahs(text, top_k=10)

        # Phase 3: Search within candidate surahs
        for surah_num in candidate_surahs:
            for v in self.db.get_surah(surah_num):
                score = ratio(text, v["text_clean"])
                if score > best_score:
                    best_score = score
                    best = {**v, "score": score}

        if best and best_score >= threshold:
            self._last_surah = best["surah"]
            self._last_ayah = best["ayah"]
            return best

        return None

    def _search_nearby(self, text: str) -> dict | None:
        best = None
        best_score = 0.0
        # Check current surah, ayahs around last position
        surah_verses = self.db.get_surah(self._last_surah)
        start = max(0, (self._last_ayah or 1) - 3)
        end = min(len(surah_verses), (self._last_ayah or 1) + 5)
        for v in surah_verses[start:end]:
            score = ratio(text, v["text_clean"])
            if score > best_score:
                best_score = score
                best = {**v, "score": score}
        return best

    def _narrow_surahs(self, text: str, top_k: int = 10) -> list[int]:
        words = set(text.split())
        surah_scores = {}
        for surah_num, verses in self.db._by_surah.items():
            score = 0
            for v in verses:
                verse_words = set(v["text_clean"].split())
                overlap = len(words & verse_words)
                if overlap > score:
                    score = overlap
            surah_scores[surah_num] = score
        ranked = sorted(surah_scores, key=surah_scores.get, reverse=True)
        return ranked[:top_k]

    def reset(self):
        self._last_surah = None
        self._last_ayah = None
```

**Step 4: Run tests**

```bash
cd ~/ai/projects/offline-tarteel && .venv/bin/pytest tests/test_matcher.py -v
```

Expected: PASS

**Step 5: Commit**

```bash
git add src/offline_tarteel/matcher.py tests/test_matcher.py
git commit -m "feat: add two-phase verse matcher with context tracking"
```

---

### Task 5: Transcription Engine (mlx-whisper)

**Files:**
- Create: `src/offline_tarteel/transcriber.py`
- Create: `tests/test_transcriber.py`

**Step 1: Write test**

`tests/test_transcriber.py`:

```python
import numpy as np
import pytest
from offline_tarteel.transcriber import Transcriber

@pytest.fixture(scope="module")
def transcriber():
    return Transcriber()

def test_transcriber_loads(transcriber):
    assert transcriber is not None

def test_transcribe_silence(transcriber):
    # 3 seconds of silence at 16kHz
    silence = np.zeros(16000 * 3, dtype=np.float32)
    result = transcriber.transcribe(silence)
    # Silence should produce empty or near-empty text
    assert isinstance(result, str)
```

**Step 2: Run to verify fail**

```bash
cd ~/ai/projects/offline-tarteel && .venv/bin/pytest tests/test_transcriber.py -v
```

**Step 3: Implement transcriber.py**

`src/offline_tarteel/transcriber.py`:

```python
import mlx_whisper
import numpy as np

MODEL_ID = "mlx-community/whisper-base-ar-quran"

class Transcriber:
    def __init__(self, model_id: str = MODEL_ID):
        self.model_id = model_id
        # mlx-whisper auto-downloads from HF hub on first use

    def transcribe(self, audio: np.ndarray, sample_rate: int = 16000) -> str:
        """Transcribe audio array to Arabic text.

        Args:
            audio: float32 numpy array, mono, at sample_rate Hz
            sample_rate: sample rate (default 16000)
        """
        if audio.dtype != np.float32:
            audio = audio.astype(np.float32)

        result = mlx_whisper.transcribe(
            audio,
            path_or_hf_repo=self.model_id,
            language="ar",
            fp16=True,
        )
        return result.get("text", "").strip()
```

> **Note:** The model ID might be `mlx-community/whisper-base-ar-quran` or we may need to convert `tarteel-ai/whisper-base-ar-quran` to MLX format. Step 3 should verify which is available on HF. If no MLX-format model exists, fall back to `faster-whisper` with `tarteel-ai/whisper-base-ar-quran`.

**Step 4: Run tests**

```bash
cd ~/ai/projects/offline-tarteel && .venv/bin/pytest tests/test_transcriber.py -v
```

Expected: PASS (model downloads on first run, may take a minute)

**Step 5: Commit**

```bash
git add src/offline_tarteel/transcriber.py tests/test_transcriber.py
git commit -m "feat: add mlx-whisper transcription engine"
```

---

### Task 6: Audio Loading Utility

**Files:**
- Create: `src/offline_tarteel/audio.py`
- Create: `tests/test_audio.py`

**Step 1: Write test**

`tests/test_audio.py`:

```python
import numpy as np
import pytest
from offline_tarteel.audio import load_audio

def test_load_audio_returns_float32(tmp_path):
    import soundfile as sf
    # Create a test WAV file
    samples = np.random.randn(16000).astype(np.float32)
    path = tmp_path / "test.wav"
    sf.write(str(path), samples, 16000)

    audio = load_audio(str(path))
    assert audio.dtype == np.float32
    assert len(audio) == 16000

def test_load_audio_resamples(tmp_path):
    import soundfile as sf
    # Create a 44.1kHz file, should resample to 16kHz
    samples = np.random.randn(44100).astype(np.float32)  # 1 second at 44.1kHz
    path = tmp_path / "test_44k.wav"
    sf.write(str(path), samples, 44100)

    audio = load_audio(str(path))
    assert audio.dtype == np.float32
    # Should be approximately 16000 samples (1 second at 16kHz)
    assert abs(len(audio) - 16000) < 100
```

**Step 2: Run to verify fail**

```bash
cd ~/ai/projects/offline-tarteel && .venv/bin/pytest tests/test_audio.py -v
```

**Step 3: Implement audio.py**

`src/offline_tarteel/audio.py`:

```python
import numpy as np
import librosa

TARGET_SR = 16000

def load_audio(path: str, sr: int = TARGET_SR) -> np.ndarray:
    audio, _ = librosa.load(path, sr=sr, mono=True)
    return audio.astype(np.float32)

def chunk_audio(audio: np.ndarray, chunk_seconds: float = 10.0, sr: int = TARGET_SR) -> list[np.ndarray]:
    chunk_size = int(chunk_seconds * sr)
    chunks = []
    for i in range(0, len(audio), chunk_size):
        chunk = audio[i:i + chunk_size]
        if len(chunk) > sr:  # skip chunks shorter than 1 second
            chunks.append(chunk)
    return chunks
```

**Step 4: Run tests**

```bash
cd ~/ai/projects/offline-tarteel && .venv/bin/pytest tests/test_audio.py -v
```

Expected: PASS

**Step 5: Commit**

```bash
git add src/offline_tarteel/audio.py tests/test_audio.py
git commit -m "feat: add audio loading with resampling and chunking"
```

---

### Task 7: CLI Entry Point

**Files:**
- Create: `src/offline_tarteel/cli.py`

**Step 1: Implement cli.py**

`src/offline_tarteel/cli.py`:

```python
import argparse
import sys
from offline_tarteel.audio import load_audio, chunk_audio
from offline_tarteel.transcriber import Transcriber
from offline_tarteel.matcher import VerseMatcher


def main():
    parser = argparse.ArgumentParser(description="Offline Quran verse recognition")
    parser.add_argument("audio_file", help="Path to audio file (MP3, WAV, etc.)")
    parser.add_argument("--model", default=None, help="HuggingFace model ID")
    parser.add_argument("--chunk-seconds", type=float, default=10.0, help="Audio chunk size in seconds")
    args = parser.parse_args()

    print(f"Loading audio: {args.audio_file}")
    audio = load_audio(args.audio_file)
    duration = len(audio) / 16000
    print(f"Duration: {duration:.1f}s")

    print("Loading model...")
    transcriber = Transcriber(model_id=args.model) if args.model else Transcriber()
    matcher = VerseMatcher()

    chunks = chunk_audio(audio, chunk_seconds=args.chunk_seconds)
    print(f"Processing {len(chunks)} chunk(s)...\n")

    for i, chunk in enumerate(chunks):
        chunk_dur = len(chunk) / 16000
        print(f"--- Chunk {i+1} ({chunk_dur:.1f}s) ---")

        text = transcriber.transcribe(chunk)
        print(f"Transcription: {text}")

        if text.strip():
            result = matcher.match(text)
            if result:
                print(f"Match: Surah {result['surah_name_en']} ({result['surah']}):{result['ayah']}")
                print(f"  Score: {result['score']:.2f}")
                print(f"  Text:  {result['text_uthmani']}")
            else:
                print("No match found")
        print()


if __name__ == "__main__":
    main()
```

**Step 2: Commit**

```bash
git add src/offline_tarteel/cli.py
git commit -m "feat: add CLI entry point for audio file recognition"
```

---

### Task 8: Download Test Audio and End-to-End Test

**Files:**
- Create: `scripts/download_test_audio.py`
- Create: `tests/test_e2e.py`

**Step 1: Write download script**

`scripts/download_test_audio.py` downloads a few test verses from EveryAyah.com:

```python
import urllib.request
from pathlib import Path

BASE_URL = "https://everyayah.com/data/Alafasy_128kbps"
TEST_DIR = Path(__file__).parent.parent / "data" / "test_audio"
TEST_DIR.mkdir(parents=True, exist_ok=True)

TESTS = [
    ("001001", "Al-Fatiha ayah 1 (Basmala)"),
    ("001002", "Al-Fatiha ayah 2"),
    ("002255", "Ayat al-Kursi"),
    ("112001", "Al-Ikhlas ayah 1"),
]

for code, desc in TESTS:
    url = f"{BASE_URL}/{code}.mp3"
    out = TEST_DIR / f"{code}.mp3"
    if out.exists():
        print(f"Already exists: {out}")
        continue
    print(f"Downloading {desc}: {url}")
    urllib.request.urlretrieve(url, out)
    print(f"  Saved: {out}")

print("Done!")
```

**Step 2: Run download**

```bash
cd ~/ai/projects/offline-tarteel && python scripts/download_test_audio.py
```

**Step 3: Write e2e test**

`tests/test_e2e.py`:

```python
import pytest
from pathlib import Path
from offline_tarteel.audio import load_audio
from offline_tarteel.transcriber import Transcriber
from offline_tarteel.matcher import VerseMatcher

TEST_AUDIO = Path(__file__).parent.parent / "data" / "test_audio"

@pytest.fixture(scope="module")
def transcriber():
    return Transcriber()

@pytest.fixture(scope="module")
def matcher():
    return VerseMatcher()

@pytest.mark.skipif(not (TEST_AUDIO / "001001.mp3").exists(), reason="Test audio not downloaded")
def test_recognize_basmala(transcriber, matcher):
    audio = load_audio(str(TEST_AUDIO / "001001.mp3"))
    text = transcriber.transcribe(audio)
    result = matcher.match(text)
    assert result is not None
    assert result["surah"] == 1
    assert result["ayah"] == 1

@pytest.mark.skipif(not (TEST_AUDIO / "002255.mp3").exists(), reason="Test audio not downloaded")
def test_recognize_ayat_al_kursi(transcriber, matcher):
    audio = load_audio(str(TEST_AUDIO / "002255.mp3"))
    text = transcriber.transcribe(audio)
    result = matcher.match(text)
    assert result is not None
    assert result["surah"] == 2
    assert result["ayah"] == 255

@pytest.mark.skipif(not (TEST_AUDIO / "112001.mp3").exists(), reason="Test audio not downloaded")
def test_recognize_ikhlas(transcriber, matcher):
    audio = load_audio(str(TEST_AUDIO / "112001.mp3"))
    text = transcriber.transcribe(audio)
    result = matcher.match(text)
    assert result is not None
    assert result["surah"] == 112
    assert result["ayah"] == 1
```

**Step 4: Run e2e tests**

```bash
cd ~/ai/projects/offline-tarteel && .venv/bin/pytest tests/test_e2e.py -v -s
```

Expected: PASS for all 3 tests (basmala, ayat al-kursi, ikhlas)

**Step 5: Run the CLI manually as a final smoke test**

```bash
cd ~/ai/projects/offline-tarteel && .venv/bin/python -m offline_tarteel.cli data/test_audio/002255.mp3
```

Expected output should show:
- Transcription of Arabic text
- Match: Surah Al-Baqara (2):255
- Score > 0.6

**Step 6: Commit**

```bash
git add scripts/download_test_audio.py tests/test_e2e.py
git commit -m "feat: add e2e tests with real Quran audio from EveryAyah"
```

---

## Verification

After all tasks are complete:

1. `cd ~/ai/projects/offline-tarteel && .venv/bin/pytest -v` - all tests pass
2. `recognize data/test_audio/002255.mp3` - correctly identifies Ayat al-Kursi
3. `recognize data/test_audio/001001.mp3` - correctly identifies Al-Fatiha:1
4. `recognize data/test_audio/112001.mp3` - correctly identifies Al-Ikhlas:1

## Fallback Note

If `mlx-whisper` cannot load the Tarteel model (no MLX-format weights available), switch to `faster-whisper`:

1. Replace `mlx-whisper` with `faster-whisper` in pyproject.toml
2. In transcriber.py, use:
   ```python
   from faster_whisper import WhisperModel
   model = WhisperModel("tarteel-ai/whisper-base-ar-quran", device="auto", compute_type="float16")
   segments, _ = model.transcribe(audio, language="ar")
   text = " ".join(s.text for s in segments)
   ```
